{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Framework\n",
    "\n",
    "### 1. Target Definition\n",
    "- News signals are generally short-lived; therefore, the focus is on **short-horizon SPY returns**.\n",
    "- The prediction horizon is **determined during the feature analysis stage**, prior to model training and portfolio backtesting.\n",
    "\n",
    "### 2. Data Preparation & Alignment\n",
    "- Ingest the news dataset and aggregate headlines to a **daily frequency**.\n",
    "- Align news features with SPY returns using a **one-day lag** to avoid look-ahead bias, given the absence of intraday timestamps and the possibility that some headlines are released after market close.\n",
    "\n",
    "### 3. Feature Construction & Economic Intuition\n",
    "- **News volume:** Daily headline counts as a proxy for information flow and market activity.\n",
    "- **Sentiment:**\n",
    "  - Counts of positive, negative, and neutral headlines\n",
    "  - Average sentiment score\n",
    "  - Constructed at both the **aggregate level** and the **category level** (category counts and category-level sentiment)\n",
    "- **Complexity:** Measures of headline complexity, where unusually complex or long headlines may signal more impactful information.\n",
    "- All features are **normalized using rolling time-series z-scores** with a 90-day window and **winsorized at the 1st and 99th percentiles**.\n",
    "\n",
    "### 4. Modeling Choices\n",
    "- **Sentiment:** Use `twitter-roberta-base-sentiment`, a well-validated model optimized for short, headline-style text, as a strong and reproducible baseline.\n",
    "- **Complexity:** Use readability-based proxies (e.g., Gunning Fog, Dale\u2013Chall, Flesch) and finance-oriented complexity lexicons where applicable.\n",
    "\n",
    "### 5. Feature-Level Analysis\n",
    "- Evaluate the standalone behavior of individual features using **Sharpe ratios** and **correlation-based metrics**.\n",
    "\n",
    "### 6. Modeling Process\n",
    "- Apply **time-series-based cross-validation** throughout.\n",
    "- Evaluate a focused set of models, including **XGBoost**, **Random Forest**, and **LightGBM**.\n",
    "- Explore **model ensembling** to combine complementary signals.\n",
    "\n",
    "### 7. Prediction Assessment\n",
    "- Analyze and visualize predictive performance across models using **R\u00b2** and **RMSE**.\n",
    "- Evaluate **risk-neutralized prediction performance** by regressing out common equity risk factors using data from the **Kenneth French Data Library**.\n",
    "\n",
    "### 8. Portfolio Construction & Backtesting\n",
    "- Construct **long\u2013short portfolios** based on individual model predictions as well as the ensemble signal.\n",
    "- Analyze backtest performance (e.g., Sharpe ratio, drawdown, turnover).\n",
    "- Assess **factor-neutral portfolio performance** after neutralizing common risk factors using data from the Kenneth French Data Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Run this cell first if you encounter ModuleNotFoundError\n",
    "# Option 1: Install from requirements.txt (recommended)\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "# Option 2: Install packages individually (including safetensors to avoid torch version issues)\n",
    "# Uncomment the line below to install all packages:\n",
    "# !pip install pandas \"numpy>=1.23.0,<2.0.0\" scikit-learn transformers torch safetensors textstat matplotlib seaborn yfinance xgboost lightgbm\n",
    "\n",
    "# Option 3: Install via terminal/command line:\n",
    "# pip install -r requirements.txt\n",
    "\n",
    "# Quick install for missing packages:\n",
    "# !pip install yfinance        # For downloading SPY data\n",
    "# !pip install xgboost         # For XGBoost model\n",
    "# !pip install lightgbm        # For LightGBM model\n",
    "\n",
    "# IMPORTANT NOTES:\n",
    "# 1. NumPy Compatibility: PyTorch 2.2.2 requires NumPy < 2.0.0. If you encounter NumPy 2.x compatibility errors,\n",
    "#    downgrade NumPy: !pip install \"numpy<2.0.0\"\n",
    "# 2. If you encounter a ValueError about torch.load requiring torch>=2.6,\n",
    "#    install safetensors: !pip install safetensors\n",
    "#    The notebook will automatically use safetensors if available to bypass the torch version requirement.\n",
    "# 3. PyArrow is required for sentiment caching (parquet file support):\n",
    "#    If using conda: !conda install -c conda-forge pyarrow\n",
    "#    If using pip: !pip install pyarrow\n",
    "#    Or install from requirements.txt which includes pyarrow\n",
    "# 4. yfinance is required for downloading SPY data:\n",
    "#    !pip install yfinance\n",
    "# 5. xgboost and lightgbm are required for model training:\n",
    "#    !pip install xgboost lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Sentiment Analysis for SPY Returns Prediction\n",
    "# This notebook implements a comprehensive pipeline for predicting next-day SPY returns\n",
    "# using news sentiment, volume, complexity, and uncertainty features\n",
    "\n",
    "# Standard library imports\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Date/time utilities\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set style for plots\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    try:\n",
    "        plt.style.use('seaborn-darkgrid')\n",
    "    except:\n",
    "        plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Function Definitions\n",
    "\n",
    "All analysis functions are defined below for modularity and reusability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Preparation\n",
    "from data_loader import DataLoader\n",
    "print(\"DataLoader class imported!\")\n",
    "\n",
    "# DATA EXPLORATION AND STATISTICS FUNCTIONS\n",
    "from data_explorer import DataExplorer\n",
    "print(\"DataExplorer class imported!\")\n",
    "\n",
    "# FEATURE ENGINEERING FUNCTIONS (on individual articles)\n",
    "from feature_extractor import ArticleFeatureExtractor\n",
    "print(\"Feature extraction class imported!\")\n",
    "\n",
    "# # FEATURE AGGREGATION, NORMALIZATION, AND ANALYSIS\n",
    "from feature_analyzer import FeatureAnalyzer\n",
    "print(\"FeatureAnalyzer class imported!\")\n",
    "\n",
    "# MODELING FUNCTIONS\n",
    "from model import NewsSentimentModeler\n",
    "print(\"NewsSentimentModeler class imported!\")\n",
    "\n",
    "# BACKTESTING FUNCTIONS\n",
    "from strategy_backtest import StrategyBacktester\n",
    "print(\"StrategyBacktester class imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation\n",
    "\n",
    "### 1.1 Load News Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load news dataset using DataLoader class\n",
    "data_loader = DataLoader()\n",
    "df_news = data_loader.load_news_dataset()\n",
    "df_news.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and display statistics\n",
    "data_explorer = DataExplorer()\n",
    "df_news, daily_counts, monthly_counts, category_counts = data_explorer.compute_news_statistics(df_news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "data_explorer.plot_news_statistics(df_news, daily_counts, monthly_counts, category_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Summary\n",
    "\n",
    "### 1. News Volume Over Time\n",
    "- From **2012 to mid-2018**, the dataset exhibits a **stable and high daily volume** of news articles, averaging roughly **80\u2013100 articles per day**, with moderate short-term fluctuations.\n",
    "- Around **mid-2018**, there is a **sharp structural break**, after which daily article counts drop dramatically to fewer than **10 articles per day**.\n",
    "- This discontinuity likely reflects a **data collection or coverage change**, rather than a genuine collapse in news production.\n",
    "- **Implication:** Post-2018 data may not be directly comparable to earlier periods, requiring regime-aware modeling or robustness checks.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Category Composition Over Time\n",
    "- Prior to 2018, **Politics, Wellness, Entertainment, and Lifestyle-related categories** dominate overall article volume.\n",
    "- The category mix is relatively stable over time, with cyclical variation within individual categories.\n",
    "- After 2018, article counts across **all categories decline simultaneously**, reinforcing the interpretation of a **dataset-level structural break**.\n",
    "- **Implication:** Category-level features are more informative pre-2018 and may suffer from sparsity afterward.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Category Distribution (Cross-Section)\n",
    "- **Politics** is by far the most frequent category, followed by **Wellness** and **Entertainment**.\n",
    "- Business-related articles represent a **smaller fraction** of total headlines.\n",
    "- This skew suggests that predictive signals extracted from the dataset are likely driven by **broad risk sentiment and macro narratives**, rather than firm-level fundamentals.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Headline Length Distribution\n",
    "- Headline length is tightly distributed, with:\n",
    "  - **Mean \u2248 9.6 tokens**\n",
    "  - **Median \u2248 10 tokens**\n",
    "- The narrow distribution indicates headlines are **short and standardized**\n",
    "- Extreme outliers are rare, reducing noise from anomalously long text.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Headline Length Over Time (Complexity Proxy)\n",
    "- Average headline length increases gradually from **2012 to 2018**, rising from approximately **8.7 to 11 tokens**.\n",
    "- After 2018, headline length stabilizes around **11 tokens**, with modest month-to-month variation.\n",
    "- This suggests a **slow shift in editorial style** toward more descriptive or nuanced headlines.\n",
    "- **Implication:** Raw complexity measures are non-stationary; relative or demeaned features are preferred.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Implications for Feature Engineering and Modeling\n",
    "- The **2018 structural break** is the most significant characteristic of the dataset and should be explicitly addressed.\n",
    "- Volume-based features require **normalization or regime-aware interpretation**.\n",
    "- Sentiment, complexity, and uncertainty features are well-defined given the consistency in headline length.\n",
    "- Relative (\u201csurprise\u201d) features are likely more informative than absolute levels due to long-term stylistic drift.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Takeaway\n",
    "Overall, the dataset exhibits **stable structure and rich variation prior to 2018**, making it well-suited for extracting short-horizon news-based signals. In contrast, the **post-2018 period shows a clear structural shift**, which may partly reflect **data sourcing or coverage changes** rather than genuine regime effects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SPY returns data using DataLoader class\n",
    "df_spy = data_loader.load_spy_returns()\n",
    "print(f\"\\nDataset shape: {df_spy.shape}\")\n",
    "print(f\"Columns: {list(df_spy.columns)}\")\n",
    "df_spy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation\n",
    "\n",
    "### 1.1 Load News Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ArticleFeatureExtractor(data_loader=data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features on individual articles\n",
    "# Create ArticleFeatureExtractor instance (sentiment model will be initialized automatically)\n",
    "df_features = extractor.compute_all_features(df_news, reload_cache=True)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Aggregation, Normalization, and Analysis\n",
    "\n",
    "This section aggregates article-level features to daily frequency, merges with category-specific features, applies normalization, aligns with SPY returns, and performs feature analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate and normalize features (daily + by category)\n",
    "# This function:\n",
    "# 1. Aggregates features to daily frequency (overall)\n",
    "# 2. Aggregates features to daily frequency by category  \n",
    "# 3. Merges both with category_feature_name columns\n",
    "# 4. Applies rolling window z-score normalization\n",
    "feature_analyzer = FeatureAnalyzer()\n",
    "daily_features = feature_analyzer.aggregate_and_normalize_features(\n",
    "    df_features,\n",
    "    window_size=90,\n",
    "    min_periods=30\n",
    ")\n",
    "print(f\"\\nFeatures shape: {daily_features.shape}\")\n",
    "print(f\"Feature columns: {len([c for c in daily_features.columns if c != 'date'])}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "daily_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align features with SPY returns using one-day lag\n",
    "# Features from day t-1 are used to predict returns on day t\n",
    "df_merged = feature_analyzer.align_features_with_spy(daily_features, df_spy)\n",
    "print(f\"\\nMerged dataset shape: {df_merged.shape}\")\n",
    "print(f\"Date range: {df_merged['date'].min()} to {df_merged['date'].max()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only *_normalized_lag features and remove the '_normalized_lag' suffix from column names\n",
    "# This keeps only the normalized lagged features for modeling\n",
    "normalized_lag_cols = [col for col in df_merged.columns if col.endswith('_normalized_lag')]\n",
    "\n",
    "# Create a new dataframe with only normalized lagged features\n",
    "df_features_clean = df_merged[['date', 'spy_return', 'spy_return_next'] + normalized_lag_cols].copy()\n",
    "\n",
    "# Remove '_normalized_lag' suffix from feature column names\n",
    "rename_dict = {col: col.replace('_normalized_lag', '') for col in normalized_lag_cols}\n",
    "df_features_clean = df_features_clean.rename(columns=rename_dict)\n",
    "\n",
    "print(f\"Kept {len(normalized_lag_cols)} normalized lagged features\")\n",
    "print(f\"Final dataset shape: {df_features_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizon Analysis\n",
    "\n",
    "Evaluate multiple forward return horizons (e.g., 1D, 2D, 3D, 4D, 5D, 7D, 10D, 14D) to determine the most appropriate prediction target for news-derived signals.  \n",
    "For each horizon, we assess signal alignment and tradeability **in the following priority order**:\n",
    "\n",
    "1. **Sharpe (primary):** long\u2013short strategy Sharpe constructed from each feature/signal group  \n",
    "2. **Spearman (secondary):** rank-based association between features and forward returns  \n",
    "3. **Pearson (tertiary):** linear correlation between features and forward returns  \n",
    "\n",
    "Results are summarized by signal category (sentiment, complexity, token-length, volume) to capture differences in information decay across feature families. The selected horizon is fixed before model training and backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df_features_clean.columns \n",
    "                       if col not in ['date', 'spy_return', 'spy_return_next']]\n",
    "feature_groups = feature_analyzer.generate_feature_groups(feature_cols)\n",
    "horizons = [1, 2, 3, 4, 5, 7, 10, 14]\n",
    "results = feature_analyzer.analyze_horizon_selection(df_features_clean, feature_groups, horizons)\n",
    "feature_analyzer.plot_horizon_analysis(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizon Selection Summary (Sharpe-First)\n",
    "\n",
    "\n",
    "- The **1-day horizon** ranks highest overall, driven by the strongest median Sharpe and broad participation across features.\n",
    "- **2\u20134 day horizons** form a secondary tier, showing moderate but decaying signal strength.\n",
    "- Horizons **beyond 5 days** consistently underperform, with median Sharpe turning negative across most signal groups.\n",
    "\n",
    "By signal type:\n",
    "- **Complexity signals** exhibit strong short-horizon behavior (1\u20133 days) with rapid decay.\n",
    "- **Sentiment signals** are more persistent, remaining positive across short to medium horizons.\n",
    "- **Token-length and volume features** show weak performance across all horizons.\n",
    "\n",
    "Based on these results, the **1-day forward return** is selected as the primary prediction target.\n",
    "**Token-length and volume-based features are excluded from the modeling stage.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all features that end with _token_length and _headline_count\n",
    "df_features_clean = df_features_clean.drop(columns=[col for col in df_features_clean.columns if col.endswith('_token_length') or col.endswith('_headline_count')])\n",
    "feature_cols_clean = [c for c in df_features_clean.columns if c not in ['date', 'spy_return', 'spy_return_next']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Feature-Level Analysis\n",
    "\n",
    "Use data from 2012 to 2018 to Evaluate the standalone behavior of individual features using correlation and information coefficients, complemented by simple long\u2013short return analyses, to assess their directional consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all features and create summary table\n",
    "\n",
    "df_features_is = df_features_clean[df_features_clean['date'] < '2019-12-31'].copy()\n",
    "feature_analysis_results = feature_analyzer.analyze_all_features(df_features_is)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Visualization\n",
    "\n",
    "Visualize the top features ranked by different performance measures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 30 features by Sharpe ratio\n",
    "feature_analyzer.plot_top_features(feature_analysis_results, measure='sharpe_ratio', top_n=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 30 features by Pearson correlation\n",
    "feature_analyzer.plot_top_features(feature_analysis_results, measure='spearman_r', top_n=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 30 features by Pearson correlation\n",
    "feature_analyzer.plot_top_features(feature_analysis_results, measure='pearson_r', top_n=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature Pairwise Correlation Analysis\n",
    "\n",
    "Analyze correlations between features to identify multicollinearity and redundant features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pairwise correlations between features\n",
    "corr_matrix, top_correlations = feature_analyzer.analyze_pairwise_correlations(\n",
    "    df_features_is, \n",
    "    feature_cols=feature_cols_clean,\n",
    "    method='pearson',\n",
    "    figsize=(16, 14),\n",
    "    top_pairs=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature distributions\n",
    "stats_df = feature_analyzer.analyze_feature_distributions(df_features_is, feature_cols_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis Summary (Exploratory Diagnostics)\n",
    "\n",
    "This section summarizes what is learned from basic distribution and correlation diagnostics on the engineered daily news features (overall + per-category).\n",
    "\n",
    "### Dataset coverage\n",
    "- **~210 engineered features** are created over **~1,992 daily observations**.\n",
    "\n",
    "### Scale and normalization\n",
    "- Core aggregated features such as `sentiment_score`, `sentiment_ratio`, `complexity` appear **roughly standardized** (means near 0, standard deviations near 1).  \n",
    "\n",
    "### Feature distributions: non-Gaussian + sparsity effects\n",
    "- Many features are **approximately symmetric** (skewness near 0), but a meaningful subset exhibits **heavy tails / outliers** (high kurtosis).\n",
    "\n",
    "### High correlation of some features\n",
    "- Pairwise correlations are high for some features like sentiment ratio and sentiment score, not suitable for standard OLS model\n",
    "\n",
    "### Feature-Level Performance Summary (Sharpe & Spearman R & Pearson R)\n",
    "\n",
    "The strongest positive Pearson correlations with next-day S&P 500 returns are observed in sentiment-based features.\n",
    "\n",
    "In contrast, the most negative Pearson correlations are associated with complexity-related features.\n",
    "\n",
    "### Cross-Metric Observations\n",
    "\n",
    "- Sentiment-based features (both aggregate and category-level) appear frequently among the top-ranked features in **both Pearson correlation and Sharpe ratio**.\n",
    "- Complexity features exhibit mixed behavior: some perform strongly on a Sharpe basis despite weaker linear correlation, while others consistently rank near the bottom across both metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training and Evaluation\n",
    "\n",
    "This section trains predictive models using Random Forest, XGBoost, and LightGBM with time series cross-validation. Models are evaluated on test (2020-2021) and out-of-sample (2022) sets. An ensemble model (weighted: 80% XGBoost, 10% LightGBM, 10% Random Forest) is also included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete modeling pipeline\n",
    "# This will:\n",
    "# 1. Split data into train (2012-2019), test (2020-2021), and out-of-sample (2022) sets\n",
    "# 2. Check if hyperparameters file exists - if yes, load models; if no, train with TSCV\n",
    "# 3. Evaluate all models (including ensemble) on test and out-of-sample sets\n",
    "# 4. Return results summary\n",
    "\n",
    "modeler = NewsSentimentModeler()\n",
    "# remove all features that end with _token_length and _headline_count\n",
    "df_features_clean = df_features_clean.drop(columns=[col for col in df_features_clean.columns if col.endswith('_token_length') or col.endswith('_headline_count')])\n",
    "results_summary = modeler.run_full_pipeline(\n",
    "    df_features_clean,\n",
    "    cv_folds=5,\n",
    "    hyperparameters_file='model_hyperparameters.json', \n",
    "    overwrite=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(results_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance across all models\n",
    "# Shows R\u00b2 and RMSE comparisons across CV, test, and out-of-sample sets\n",
    "modeler.visualize_model_performance(figsize=(14, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction Results Summary\n",
    "\n",
    "We evaluate three individual models (Random Forest, XGBoost, LightGBM) and a weighted ensemble (80% XGBoost, 10% LightGBM, 10% Random Forest) using time-series cross-validation, a held-out test set (2020\u20132021), and a fully out-of-sample period (2022).\n",
    "\n",
    "### Cross-Validation Performance\n",
    "- All models exhibit **negative cross-validated R\u00b2**, indicating limited stable predictive power in rolling training windows.\n",
    "- Tree-based models (Random Forest, XGBoost, LightGBM) show variability across folds.\n",
    "\n",
    "### Test Set Performance (2020\u20132021)\n",
    "- Test-set R\u00b2 values are **near zero across all models**, with some models achieving marginally positive R\u00b2.\n",
    "- RMSE and MAE are very similar across models, suggesting comparable error magnitudes.\n",
    "- Directional accuracy on the test set is consistently **above 56%** for all models, indicating some ability to capture short-term return direction despite weak linear fit.\n",
    "\n",
    "### Out-of-Sample Performance (2022)\n",
    "- All models show **negative out-of-sample R\u00b2**, reflecting deterioration in explanatory power when evaluated on unseen data.\n",
    "- RMSE remains stable relative to the test period, indicating no significant increase in prediction error magnitude.\n",
    "- Directional accuracy converges to **~43.7% across all models**, consistent with reduced signal strength in the most recent period.\n",
    "\n",
    "### Ensemble Results\n",
    "- The weighted ensemble (80% XGBoost, 10% LightGBM, 10% Random Forest) provides a combination of model predictions.\n",
    "\n",
    "### Overall Takeaways\n",
    "- Predictive performance is **weak in terms of R\u00b2**, which is typical for next-day index return forecasting.\n",
    "- Directional accuracy above 50% in-sample does not consistently persist out-of-sample.\n",
    "- The results motivate:\n",
    "  - Careful signal normalization and portfolio construction,\n",
    "  - Risk-controlled trading strategies,\n",
    "  - And further exploration of non-linear interactions or regime-dependent behavior rather than reliance on raw point forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Strategy Construction and Backtesting\n",
    "\n",
    "This section constructs long-short trading strategies based on model predictions, analyzes backtest performance, and assesses factor-neutral portfolio performance.\n",
    "\n",
    "### Strategy Design\n",
    "\n",
    "The trading strategy is designed as a **directional long-short portfolio** on SPY using model predictions. Since SPY is a single asset, \"long-short\" here means directional exposure that can flip sign (long, short, or flat), not cross-sectional ranking. The strategy construction follows these steps:\n",
    "\n",
    "#### Step 1: Signal Normalization\n",
    "Model predictions are normalized using a **rolling window z-score** to ensure stable position sizing over time:\n",
    "- **Z-score normalization**: `z_t = (prediction_t - \u03bc_t^(L)) / \u03c3_t^(L)`\n",
    "  - `\u03bc_t^(L)`, `\u03c3_t^(L)`: Rolling mean and standard deviation over a **60-day window**\n",
    "  - Minimum periods required: 30 days\n",
    "  - This removes trends and makes signals comparable across time periods\n",
    "  - Early periods with insufficient history are filled with 0 (neutral position)\n",
    "\n",
    "#### Step 2: Position Construction\n",
    "Positions are computed from the normalized signal using **discrete exposure**:\n",
    "\n",
    "**Discrete Position Rule**:\n",
    "- `w_t = +1` (100% long) if `z_t > threshold`\n",
    "- `w_t = -1` (100% short) if `z_t < -threshold`\n",
    "- `w_t = 0` (flat/neutral) otherwise\n",
    "- **Threshold used: 1.5** (z-score units)\n",
    "\n",
    "This means positions are only taken when the normalized signal is strong enough (more than 1.5 standard deviations from the rolling mean). This conservative threshold reduces trading frequency and focuses on high-conviction signals.\n",
    "\n",
    "#### Step 3: Portfolio Return Calculation\n",
    "Daily portfolio returns are computed as:\n",
    "- **Gross return**: `r_port_t+1 = w_t \u00b7 r_SPY_t+1`\n",
    "  - Accounts for trading costs from position changes (only charged when position changes from flat to long/short or vice versa)\n",
    "\n",
    "#### Step 4: Performance Evaluation\n",
    "The strategy is evaluated using comprehensive metrics:\n",
    "- **Return metrics**: Annualized return, total return\n",
    "- **Risk metrics**: Annualized volatility, max drawdown, Calmar ratio\n",
    "- **Risk-adjusted**: Sharpe ratio\n",
    "- **Trading metrics**: Turnover, hit rate, win rate, profit factor\n",
    "- **Factor-neutral**: Alpha and risk-adjusted returns after neutralizing Fama-French factors (MKT-RF, SMB, HML)\n",
    "\n",
    "#### Key Design Principles\n",
    "1. **No look-ahead bias**: Only uses information available at time `t` to predict returns at `t+1`\n",
    "2. **Stable position sizing**: Rolling normalization prevents signal drift\n",
    "3. **Conservative threshold**: Using threshold=1.5 ensures positions are only taken on strong signals, reducing false positives\n",
    "4. **Discrete positions**: Binary positions (+1, -1, 0) simplify execution and reduce sensitivity to signal magnitude\n",
    "6. **Factor-neutral analysis**: Isolates alpha from common risk factors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for strategy backtesting\n",
    "# Use test + out-of-sample data (2020-2022) for backtesting\n",
    "df_backtest = df_features_clean[\n",
    "    (df_features_clean['date'] >= '2020-01-01') & \n",
    "    (df_features_clean['date'] <= '2021-12-31')\n",
    "].copy()\n",
    "\n",
    "print(f\"Backtest period: {df_backtest['date'].min()} to {df_backtest['date'].max()}\")\n",
    "print(f\"Number of observations: {len(df_backtest):,}\")\n",
    "\n",
    "# Prepare feature matrix and get SPY returns\n",
    "X_backtest, y_backtest, feature_cols_backtest = modeler.prepare_features_target(df_backtest)\n",
    "spy_returns_backtest = df_backtest['spy_return_next'].values\n",
    "dates_backtest = df_backtest['date'].values\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X_backtest.shape}\")\n",
    "print(f\"SPY returns shape: {spy_returns_backtest.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from all models and ensemble\n",
    "predictions = modeler.generate_predictions(X_backtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize backtester\n",
    "backtester = StrategyBacktester()\n",
    "\n",
    "# Backtest each strategy\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BACKTESTING STRATEGIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_name, pred in predictions.items():\n",
    "    print(f\"\\nBacktesting {model_name.upper().replace('_', ' ')} strategy...\")\n",
    "    \n",
    "    try:\n",
    "        results = backtester.backtest_strategy(\n",
    "            predictions=pred,\n",
    "            spy_returns=spy_returns_backtest,\n",
    "            dates=dates_backtest,\n",
    "            normalization='zscore',\n",
    "            window=60,\n",
    "            k=0.5,\n",
    "            w_max=1.0,\n",
    "            position_type='discrete',\n",
    "            threshold=1.5,\n",
    "            vol_targeting=False,\n",
    "            strategy_name=model_name\n",
    "        )\n",
    "        \n",
    "        # Print key metrics\n",
    "        metrics = results['metrics']\n",
    "        print(f\"  Sharpe Ratio: {metrics['sharpe_ratio']:.3f}\")\n",
    "        print(f\"  Annualized Return: {metrics['annualized_return']:.2%}\")\n",
    "        print(f\"  Max Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "        print(f\"  Turnover: {metrics['turnover']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error backtesting {model_name}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BACKTESTING COMPLETE\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all strategies\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df = backtester.compare_strategies()\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize strategy comparison\n",
    "backtester.plot_strategy_comparison(figsize=(16, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detailed performance for each strategy\n",
    "for strategy_name in backtester.strategies.keys():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Detailed Performance: {strategy_name.upper().replace('_', ' ')}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    backtester.plot_strategy_performance(strategy_name, figsize=(16, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Factor-Neutral Analysis\n",
    "\n",
    "Assess portfolio performance after neutralizing common risk factors using Fama-French factors from the Kenneth French Data Library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run factor-neutral analysis for all strategies\n",
    "# Note: To perform factor-neutral analysis, download Fama-French factors from:\n",
    "# https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html\n",
    "# Save as CSV with columns: date, MKT-RF, SMB, HML, RF (or similar format)\n",
    "\n",
    "french_factors_path = 'data/F-F_Research_Data_5_Factors_2x3_daily.csv'  # Update this path if you have French factors file\n",
    "# Example: french_factors_path = 'data/french_factors.csv'\n",
    "\n",
    "# Run complete factor-neutral analysis\n",
    "factor_results = backtester.run_factor_neutral_analysis(\n",
    "    french_factors_path=french_factors_path,\n",
    "    factors=['MKT-RF', 'SMB', 'HML']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pure Out-of-Sample Analysis (2022+)\n",
    "\n",
    "This section evaluates the ensemble model and strategy backtesting on pure out-of-sample data (2022-01-01 and onwards).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare pure out-of-sample data (2022-01-01 and onwards)\n",
    "df_oos_pure = df_features_clean[\n",
    "    df_features_clean['date'] >= '2022-01-01'\n",
    "].copy()\n",
    "\n",
    "print(f\"Pure out-of-sample period: {df_oos_pure['date'].min()} to {df_oos_pure['date'].max()}\")\n",
    "print(f\"Number of observations: {len(df_oos_pure):,}\")\n",
    "\n",
    "# Prepare feature matrix and get SPY returns\n",
    "X_oos_pure, y_oos_pure, feature_cols_oos = modeler.prepare_features_target(df_oos_pure)\n",
    "spy_returns_oos_pure = df_oos_pure['spy_return_next'].values\n",
    "dates_oos_pure = df_oos_pure['date'].values\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X_oos_pure.shape}\")\n",
    "print(f\"SPY returns shape: {spy_returns_oos_pure.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from ensemble model on pure out-of-sample data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING ENSEMBLE PREDICTIONS ON PURE OUT-OF-SAMPLE DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "predictions_oos_pure = modeler.generate_predictions(X_oos_pure)\n",
    "\n",
    "# Focus on ensemble predictions\n",
    "if 'ensemble' in predictions_oos_pure:\n",
    "    ensemble_predictions_oos = predictions_oos_pure['ensemble']\n",
    "    print(f\"\\nEnsemble predictions shape: {ensemble_predictions_oos.shape}\")\n",
    "    print(f\"Ensemble prediction stats:\")\n",
    "    print(f\"  Mean: {np.mean(ensemble_predictions_oos):.6f}\")\n",
    "    print(f\"  Std: {np.std(ensemble_predictions_oos):.6f}\")\n",
    "    print(f\"  Min: {np.min(ensemble_predictions_oos):.6f}\")\n",
    "    print(f\"  Max: {np.max(ensemble_predictions_oos):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize backtester for out-of-sample analysis\n",
    "backtester_oos = StrategyBacktester()\n",
    "\n",
    "# Backtest ensemble strategy on pure out-of-sample data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BACKTESTING ENSEMBLE STRATEGY ON PURE OUT-OF-SAMPLE DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'ensemble' in predictions_oos_pure:\n",
    "    ensemble_results_oos = backtester_oos.backtest_strategy(\n",
    "        predictions=ensemble_predictions_oos,\n",
    "        spy_returns=spy_returns_oos_pure,\n",
    "        dates=dates_oos_pure,\n",
    "        normalization='zscore',\n",
    "        window=60,\n",
    "        k=0.5,\n",
    "        w_max=1.0,\n",
    "        position_type='continuous',\n",
    "        vol_targeting=False,\n",
    "        strategy_name='ensemble_oos_pure'\n",
    "    )\n",
    "    \n",
    "    # Print key metrics\n",
    "    metrics_oos = ensemble_results_oos['metrics']\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PURE OUT-OF-SAMPLE PERFORMANCE (Ensemble Strategy)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Annualized Return: {metrics_oos['annualized_return']:.2%}\")\n",
    "    print(f\"Annualized Volatility: {metrics_oos['annualized_volatility']:.2%}\")\n",
    "    print(f\"Sharpe Ratio: {metrics_oos['sharpe_ratio']:.3f}\")\n",
    "    print(f\"Max Drawdown: {metrics_oos['max_drawdown']:.2%}\")\n",
    "    print(f\"Calmar Ratio: {metrics_oos['calmar_ratio']:.3f}\")\n",
    "    print(f\"Hit Rate: {metrics_oos['hit_rate']:.2%}\")\n",
    "    print(f\"Turnover: {metrics_oos['turnover']:.4f}\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ensemble strategy performance on pure out-of-sample data\n",
    "if 'ensemble_oos_pure' in backtester_oos.strategies:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VISUALIZING ENSEMBLE STRATEGY PERFORMANCE\")\n",
    "    print(\"=\"*60)\n",
    "    backtester_oos.plot_strategy_performance('ensemble_oos_pure', figsize=(16, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor-neutral analysis on pure out-of-sample data\n",
    "french_factors_path_oos = 'data/F-F_Research_Data_5_Factors_2x3_daily.csv'\n",
    "\n",
    "factor_results_oos = backtester_oos.run_factor_neutral_analysis(\n",
    "    french_factors_path=french_factors_path_oos,\n",
    "    factors=['MKT-RF', 'SMB', 'HML']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pure oos data shows negative performance. Overall \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Summary and Conclusions\n",
    "\n",
    "#### Model Performance\n",
    "- **Cross-Validation**: Models show limited predictive power (negative R\u00b2) in rolling training windows, which is typical for next-day index return forecasting\n",
    "- **Test Period (2020-2021)**: Models achieve near-zero R\u00b2 but maintain directional accuracy above 56%, indicating some ability to capture short-term return direction\n",
    "- **Out-of-Sample (2022+)**: Performance deteriorates with negative R\u00b2 and directional accuracy converging to ~43.7%, consistent with reduced signal strength in recent periods\n",
    "- **Ensemble Model**: The weighted ensemble (80% XGBoost, 10% LightGBM, 10% Random Forest) combines model predictions but does not materially improve performance relative to individual models\n",
    "\n",
    "#### Strategy Performance\n",
    "- **Backtest Results**: Long-short strategies constructed from model predictions show varying performance across models\n",
    "  - Portfolio return: `r_port_t+1 = w_t \u00b7 r_SPY_t+1`\n",
    "- **Risk Metrics**: Strategies exhibit different risk-return profiles, with some showing better Sharpe ratios and lower drawdowns\n",
    "- **Out-of-Sample**: Pure out-of-sample performance (2022+) shows negative returns, highlighting the challenge of maintaining predictive power in unseen market conditions\n",
    "\n",
    "#### Factor-Neutral Analysis\n",
    "- **Factor Exposures**: Strategies show minimal exposure to common risk factors (MKT-RF, SMB, HML)\n",
    "- **Alpha**: Factor-neutral alpha is negative in out-of-sample period, indicating that returns cannot be attributed to common risk factors\n",
    "- **Risk-Adjusted Returns**: After neutralizing factors, strategies fail to generate positive risk-adjusted returns\n",
    "\n",
    "#### Key Takeaways\n",
    "1. **Predictive Power**: While models show weak R\u00b2 performance, directional accuracy above 50% in-sample suggests some signal exists\n",
    "2. **Out-of-Sample Deterioration**: Performance degradation in out-of-sample period highlights the importance of robust validation and the challenges of time-varying market regimes\n",
    "3. **Transaction Costs**: Realistic cost assumptions reveal that high-turnover strategies may not be profitable after costs\n",
    "4. **Factor Exposure**: Minimal factor exposure suggests strategies are not simply capturing common risk premia\n",
    "5. **Future Directions**: \n",
    "   - Explore regime-dependent models that adapt to changing market conditions\n",
    "   - Investigate alternative feature engineering approaches\n",
    "   - Consider longer prediction horizons or different normalization schemes\n",
    "   - Evaluate non-linear interactions and feature combinations\n",
    "\n",
    "#### Limitations\n",
    "- **Data Quality**: News data may have timing issues (some headlines published after market close)\n",
    "- **Feature Engineering**: Current features may not capture all relevant information\n",
    "- **Market Regimes**: Models trained on 2012-2019 data may not generalize to post-2020 market conditions\n",
    "- **Transaction Costs**: Assumed costs may not reflect actual implementation costs for all market participants\n",
    "\n",
    "#### Conclusion\n",
    "This analysis demonstrates a systematic approach to news sentiment-based trading strategy development. While the results show limited out-of-sample profitability, the framework provides a solid foundation for further research and improvement. The negative performance in recent periods underscores the importance of continuous model validation and adaptation to changing market conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}